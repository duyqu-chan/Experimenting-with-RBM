{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import ssl\n",
    "import os\n",
    "import socket\n",
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and set the project root directory as the current working directory\n",
    "project_root = Path().resolve().parent\n",
    "os.chdir(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ModelKod</th>\n",
       "      <th>UrunOptionRef</th>\n",
       "      <th>CepDetayi</th>\n",
       "      <th>KolBoyu</th>\n",
       "      <th>KumasDeseni</th>\n",
       "      <th>YakaTipi</th>\n",
       "      <th>LisansTanim</th>\n",
       "      <th>LisansKarakterTanim</th>\n",
       "      <th>NumuneResim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S4GO09Z8</td>\n",
       "      <td>3038464</td>\n",
       "      <td>CEPSİZ</td>\n",
       "      <td>UZUN KOL</td>\n",
       "      <td>YOK</td>\n",
       "      <td>BİSİKLET YAKA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://teknikfoy.lcwaikiki.local/ModelResim.a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S52828Z8</td>\n",
       "      <td>3302747</td>\n",
       "      <td>CEPSİZ</td>\n",
       "      <td>KISA KOL</td>\n",
       "      <td>YOK</td>\n",
       "      <td>BİSİKLET YAKA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://teknikfoy.lcwaikiki.local/ModelResim.a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>W53916Z8</td>\n",
       "      <td>3503947</td>\n",
       "      <td>CEPSİZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DÜZ</td>\n",
       "      <td>GÖMLEK YAKA+ DÜĞMELİ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://teknikfoy.lcwaikiki.local/ModelResim.a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S42345Z8</td>\n",
       "      <td>2900784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KISA KOL</td>\n",
       "      <td>DÜZ</td>\n",
       "      <td>HAKİM YAKA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://teknikfoy.lcwaikiki.local/ModelResim.a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>W4KG67Z8</td>\n",
       "      <td>3403948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MINIMAL DESEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://teknikfoy.lcwaikiki.local/ModelResim.a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ModelKod  UrunOptionRef CepDetayi   KolBoyu    KumasDeseni  \\\n",
       "1   S4GO09Z8        3038464    CEPSİZ  UZUN KOL            YOK   \n",
       "4   S52828Z8        3302747    CEPSİZ  KISA KOL            YOK   \n",
       "7   W53916Z8        3503947    CEPSİZ       NaN            DÜZ   \n",
       "9   S42345Z8        2900784       NaN  KISA KOL            DÜZ   \n",
       "10  W4KG67Z8        3403948       NaN       NaN  MINIMAL DESEN   \n",
       "\n",
       "                YakaTipi LisansTanim LisansKarakterTanim  \\\n",
       "1          BİSİKLET YAKA         NaN                 NaN   \n",
       "4          BİSİKLET YAKA         NaN                 NaN   \n",
       "7   GÖMLEK YAKA+ DÜĞMELİ         NaN                 NaN   \n",
       "9             HAKİM YAKA         NaN                 NaN   \n",
       "10                   NaN         NaN                 NaN   \n",
       "\n",
       "                                          NumuneResim  \n",
       "1   https://teknikfoy.lcwaikiki.local/ModelResim.a...  \n",
       "4   https://teknikfoy.lcwaikiki.local/ModelResim.a...  \n",
       "7   https://teknikfoy.lcwaikiki.local/ModelResim.a...  \n",
       "9   https://teknikfoy.lcwaikiki.local/ModelResim.a...  \n",
       "10  https://teknikfoy.lcwaikiki.local/ModelResim.a...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the filename and path\n",
    "folder_path= os.path.join(project_root, 'data/processed')\n",
    "file_name = \"sample_df.csv\"\n",
    "file_path = os.path.join(folder_path, file_name)\n",
    "df = pd.read_csv(file_path)\n",
    "df = df.dropna(subset=[\"KumasDeseni\", \"NumuneResim\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6328, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6328"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.UrunOptionRef.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.KumasDeseni.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proxy ayarları\n",
    "socket.setdefaulttimeout(10)  # Zaman aşımını uzat\n",
    "proxy_support = urllib.request.ProxyHandler({\n",
    "    'http': 'http://10.62.0.168:8080',\n",
    "    'https': 'http://10.62.0.168:8080'\n",
    "})\n",
    "opener = urllib.request.build_opener(proxy_support)\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "# Proje yolları\n",
    "\n",
    "file_path = os.path.join(project_root, 'data/raw/RBM_images')\n",
    "error_log = os.path.join(project_root, 'data/raw/RBM_logs/errors.log')\n",
    "\n",
    "# Dosya yolu yoksa oluştur\n",
    "os.makedirs(file_path, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(error_log), exist_ok=True)\n",
    "\n",
    "# SSL doğrulamasını devre dışı bırak\n",
    "context = ssl._create_unverified_context()\n",
    "\n",
    "# Daha önce indirilen dosyaları atla\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Downloading Images\", unit=\"file\"):\n",
    "    image_url = row['NumuneResim'].replace(' ', '%20')  # Boşlukları encode et\n",
    "    file_name = f\"{row['UrunOptionRef']}.jpg\"  # UrunOptionRef'i dosya adı olarak kullan\n",
    "    full_path = os.path.join(file_path, file_name)  # Tam dosya yolu\n",
    "\n",
    "    # Eğer dosya zaten varsa indirmeden atla\n",
    "    if os.path.exists(full_path):\n",
    "        print(f\"Skipping {file_name} (already exists)\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Görseli indir\n",
    "        response = urllib.request.urlopen(image_url, timeout=20, context=context)\n",
    "        with open(full_path, 'wb') as out_file:\n",
    "            out_file.write(response.read())\n",
    "        print(f\"Downloaded: {file_name}\")\n",
    "    except Exception as e:\n",
    "        error_message = f\"Skipping {image_url} due to error: {e}\\n\"\n",
    "        print(error_message)\n",
    "        # Hataları log dosyasına yaz\n",
    "        with open(error_log, 'a', encoding='utf-8') as log_file:\n",
    "            log_file.write(error_message)\n",
    "\n",
    "# Hatalı dosyaların 'UrunOptionRef' değerlerini listeye ekleyin\n",
    "error_files = [3140005, 3086255, 3220628, 2928716, 3143220, 2993807, 3220105, 2953228, 3062170, 2901937]\n",
    "\n",
    "# SSL doğrulamasını devre dışı bırak\n",
    "context = ssl._create_unverified_context()\n",
    "\n",
    "# Sadece hatalı dosyaları yeniden indir\n",
    "for ref in tqdm(error_files, desc=\"Re-downloading Images\", unit=\"file\"):\n",
    "    image_url = df.loc[df['UrunOptionRef'] == ref, 'NumuneResim'].values[0].replace(' ', '%20')\n",
    "    file_name = f\"{ref}.jpg\"\n",
    "    full_path = os.path.join(file_path, file_name)\n",
    "\n",
    "    try:\n",
    "        response = urllib.request.urlopen(image_url, timeout=20, context=context)\n",
    "        with open(full_path, 'wb') as out_file:\n",
    "            out_file.write(response.read())\n",
    "        print(f\"Successfully re-downloaded: {file_name}\")\n",
    "    except Exception as e:\n",
    "        error_message = f\"Failed to re-download {ref}: {e}\\n\"\n",
    "        print(error_message)\n",
    "        with open(error_log, 'a', encoding='utf-8') as log_file:\n",
    "            log_file.write(error_message)\n",
    "\n",
    "# Disable SSL verification\n",
    "context = ssl._create_unverified_context()\n",
    "\n",
    "# Başarısız dosyaların listesini manuel olarak oluşturun\n",
    "failed_files = [\n",
    "    3140005,\n",
    "    3086255,\n",
    "    3220628,\n",
    "    2928716,\n",
    "    3143220,\n",
    "    2993807,\n",
    "    3220105,\n",
    "    2953228,\n",
    "    3062170,\n",
    "    2901937\n",
    "]\n",
    "#['3220628', '3220105', '3062170']#[\"3220628\", \"3220105\", \"3062170\"]   \n",
    "# Kayıtların saklanacağı ana dizin\n",
    "file_path = \"D:\\\\Projects\\\\attribute_extraction_from_image\\\\data\\\\raw\\\\RBM_images\"\n",
    "\n",
    "# Log dosyası (hata kayıtları için)\n",
    "error_log = os.path.join(file_path, \"error_log.txt\")\n",
    "\n",
    "# Dosyaları yeniden indir\n",
    "for file_id in tqdm(failed_files, desc=\"Re-downloading Images\", unit=\"file\"):\n",
    "    image_url = df.loc[df['UrunOptionRef'] == int(file_id), 'NumuneResim'].values[0].replace(' ', '%20')\n",
    "    file_name = f\"{file_id}.jpg\"\n",
    "    full_path = os.path.join(file_path, file_name)\n",
    "\n",
    "    try:\n",
    "        response = urllib.request.urlopen(image_url, timeout=20, context=context)\n",
    "        with open(full_path, 'wb') as out_file:\n",
    "            out_file.write(response.read())\n",
    "        print(f\"Successfully re-downloaded: {file_name}\")\n",
    "    except Exception as e:\n",
    "        error_message = f\"Failed to re-download {file_id}: {e}\\n\"\n",
    "        print(error_message)\n",
    "        # Log the error\n",
    "        with open(error_log, 'a', encoding='utf-8') as log_file:\n",
    "            log_file.write(error_message)\n",
    "\n",
    "# Hata alan dosyalar\n",
    "failed_files = [\"3220628\", \"3220105\", \"2953228\"] #3062170\n",
    "\n",
    "# Başarısız dosyaları DataFrame'den çıkar\n",
    "df_filtered = df[~df[\"UrunOptionRef\"].isin(failed_files)]\n",
    "\n",
    "df_filtered.shape\n",
    "# Hatalı id'leri liste olarak belirleyelim\n",
    "error_ids = [\n",
    "    3140005,\n",
    "    3086255,\n",
    "    3220628,\n",
    "    2928716,\n",
    "    3143220,\n",
    "    2993807,\n",
    "    3220105,\n",
    "    2953228,\n",
    "    3062170,\n",
    "    2901937\n",
    "]\n",
    "\n",
    "# Hatalı ID'leri df_filtered'dan çıkaralım\n",
    "df_filtered_cleaned = df_filtered[~df_filtered['UrunOptionRef'].isin(error_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ModelKod', 'UrunOptionRef', 'CepDetayi', 'KolBoyu', 'KumasDeseni',\n",
       "       'YakaTipi', 'LisansTanim', 'LisansKarakterTanim', 'NumuneResim',\n",
       "       'KumasDeseniEncoded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered_cleaned.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DÜZ', 'YOK', 'METRAJ BASKILI', 'BASKILI', 'ÇİZGİLİ'], dtype='object', name='KumasDeseni')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "      <th>Cumulative_Percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KumasDeseni</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DÜZ</th>\n",
       "      <td>3300</td>\n",
       "      <td>52.231719</td>\n",
       "      <td>52.231719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YOK</th>\n",
       "      <td>638</td>\n",
       "      <td>10.098132</td>\n",
       "      <td>62.329851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>METRAJ BASKILI</th>\n",
       "      <td>518</td>\n",
       "      <td>8.198797</td>\n",
       "      <td>70.528648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BASKILI</th>\n",
       "      <td>416</td>\n",
       "      <td>6.584362</td>\n",
       "      <td>77.113010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ÇİZGİLİ</th>\n",
       "      <td>400</td>\n",
       "      <td>6.331117</td>\n",
       "      <td>83.444128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MİKRO EKOSE</th>\n",
       "      <td>1</td>\n",
       "      <td>0.015828</td>\n",
       "      <td>99.936689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMBELLİSHED</th>\n",
       "      <td>1</td>\n",
       "      <td>0.015828</td>\n",
       "      <td>99.952517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KARELİ</th>\n",
       "      <td>1</td>\n",
       "      <td>0.015828</td>\n",
       "      <td>99.968344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BASKILI/DÜZ</th>\n",
       "      <td>1</td>\n",
       "      <td>0.015828</td>\n",
       "      <td>99.984172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HALLOWEEN</th>\n",
       "      <td>1</td>\n",
       "      <td>0.015828</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Count  Percentage  Cumulative_Percentage\n",
       "KumasDeseni                                             \n",
       "DÜZ              3300   52.231719              52.231719\n",
       "YOK               638   10.098132              62.329851\n",
       "METRAJ BASKILI    518    8.198797              70.528648\n",
       "BASKILI           416    6.584362              77.113010\n",
       "ÇİZGİLİ           400    6.331117              83.444128\n",
       "...               ...         ...                    ...\n",
       "MİKRO EKOSE         1    0.015828              99.936689\n",
       "EMBELLİSHED         1    0.015828              99.952517\n",
       "KARELİ              1    0.015828              99.968344\n",
       "BASKILI/DÜZ         1    0.015828              99.984172\n",
       "HALLOWEEN           1    0.015828             100.000000\n",
       "\n",
       "[71 rows x 3 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fabric = df_filtered_cleaned[['ModelKod', 'UrunOptionRef', 'KumasDeseni', 'NumuneResim']]\n",
    "\n",
    "# KumasDeseni kolonunda sınıf sayımlarını hesaplama\n",
    "category_counts = df_fabric['KumasDeseni'].value_counts()\n",
    "\n",
    "# Pareto analizi için kümülatif yüzde hesaplama\n",
    "category_percentages = (category_counts / category_counts.sum()) * 100\n",
    "category_cumulative = category_percentages.cumsum()\n",
    "\n",
    "# Veri setinin %80'ini oluşturan sınıfları bulma\n",
    "pareto_classes = category_cumulative[category_cumulative <= 85].index\n",
    "print(pareto_classes)\n",
    "\n",
    "# Sonuçları birleştirerek görselleştirme\n",
    "pareto_analysis = pd.DataFrame({\n",
    "    'Count': category_counts,\n",
    "    'Percentage': category_percentages,\n",
    "    'Cumulative_Percentage': category_cumulative\n",
    "})\n",
    "pareto_analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Türkçe sınıflar\n",
    "turkce_siniflar = [\"DÜZ\", \"EKOSE\", \"ÇİÇEKLİ\", \"GEOMETRİK\", \"HAYVAN DESENLİ\",\n",
    "                   \"MONOCROM\", \"TİPOGRAFİ\", \"PUANTİYE\", \"ETNİK\", \"TROPİK\",\n",
    "                   \"ÇİZGİLİ\", \"ŞAL DESENİ\", \"BLOK\"]\n",
    "\n",
    "# Büyük harfe çevirme\n",
    "df_fabric.loc[:, 'KumasDeseni'] = df_fabric['KumasDeseni'].str.upper()\n",
    "\n",
    "# Türkçe sınıflar dışındakileri 'DİĞER' yapma\n",
    "df_fabric.loc[:, 'KumasDeseni'] = df_fabric['KumasDeseni'].apply(lambda x: x if x in pareto_classes else 'DİĞER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Görselleri işleyen fonksiyon\n",
    "def process_image_from_id(product_id, img_dir, img_size=(64, 64)):\n",
    "    \"\"\"\n",
    "    Ürün ID'sine göre ilgili görseli işleme.\n",
    "    \n",
    "    Args:\n",
    "        product_id (str): Ürün ID'si.\n",
    "        img_dir (str): Görsellerin bulunduğu dizin yolu.\n",
    "        img_size (tuple): Görselin yeniden boyutlandırılacağı boyutlar.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Düzleştirilmiş görsel.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Görselin dosya yolunu oluştur\n",
    "        filepath = os.path.join(img_dir, f\"{product_id}.jpg\")\n",
    "        \n",
    "        # Görseli oku ve işle\n",
    "        img = Image.open(filepath).convert(\"L\")  # Gri tonlama\n",
    "        img = img.resize(img_size)  # Yeniden boyutlandır\n",
    "        return np.array(img).flatten()  # Düzleştir\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {product_id}: {e}\")\n",
    "        # Hata durumunda sıfır dolu bir görsel döndür\n",
    "        return np.zeros(img_size[0] * img_size[1])\n",
    "\n",
    "# Görsellerin bulunduğu klasör\n",
    "image_directory = os.path.join(\"data\", \"raw\", \"RBM_images\")\n",
    "\n",
    "# Görselleri işlemeye başla\n",
    "X_images = np.array([\n",
    "    process_image_from_id(product_id, image_directory)\n",
    "    for product_id in df_fabric[\"UrunOptionRef\"]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Görselleri işlemeye başla\n",
    "X_images_128 = np.array([\n",
    "    process_image_from_id(product_id, image_directory, img_size=(128, 128))\n",
    "    for product_id in df_fabric[\"UrunOptionRef\"]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi kopyalayarak çalışma\n",
    "df_fabric = df_fabric.copy()\n",
    "\n",
    "# Kumaş Deseni etiketlerini kodlama\n",
    "label_encoder = LabelEncoder()\n",
    "df_fabric[\"KumasDeseniEncoded\"] = label_encoder.fit_transform(df_fabric[\"KumasDeseni\"])\n",
    "\n",
    "# Etiketleri numpy dizisine dönüştür\n",
    "y_labels = df_fabric[\"KumasDeseniEncoded\"].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi eğitim ve test setlerine ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_images, y_labels, test_size=0.2, random_state=42, stratify=y_labels)\n",
    "\n",
    "# Veriyi normalize etme\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi eğitim ve test setlerine ayırma\n",
    "X_train_128, X_test_128, y_train, y_test = train_test_split(X_images_128, y_labels, test_size=0.2, random_state=42, stratify=y_labels)\n",
    "\n",
    "# Veriyi normalize etme\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_128 = scaler.fit_transform(X_train_128)\n",
    "X_test_128 = scaler.transform(X_test_128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction with RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm = BernoulliRBM(n_components=256, learning_rate=0.01, n_iter=10, random_state=42)\n",
    "\n",
    "# RBM ile özellik çıkarımı\n",
    "X_train_rbm = rbm.fit_transform(X_train)\n",
    "X_test_rbm = rbm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm_128 = BernoulliRBM(n_components=128, learning_rate=0.01, n_iter=10, random_state=42)\n",
    "\n",
    "# RBM ile özellik çıkarımı\n",
    "X_train_128rbm = rbm_128.fit_transform(X_train)\n",
    "X_test_128rbm = rbm_128.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm = BernoulliRBM(n_components=512, learning_rate=0.01, n_iter=10, random_state=42)\n",
    "\n",
    "# RBM ile özellik çıkarımı\n",
    "X_train_512rbm = rbm.fit_transform(X_train)\n",
    "X_test_512rbm = rbm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBM ile özellik çıkarımı\n",
    "X_train_rbm_128 = rbm.fit_transform(X_train_128)\n",
    "X_test_rbm_128 = rbm.transform(X_test_128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBM-Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "       BASKILI       0.40      0.07      0.12        83\n",
      "           DÜZ       0.53      0.97      0.69       660\n",
      "         DİĞER       0.43      0.04      0.08       209\n",
      "METRAJ BASKILI       1.00      0.01      0.02       104\n",
      "           YOK       0.56      0.11      0.18       128\n",
      "       ÇİZGİLİ       0.00      0.00      0.00        80\n",
      "\n",
      "      accuracy                           0.53      1264\n",
      "     macro avg       0.49      0.20      0.18      1264\n",
      "  weighted avg       0.52      0.53      0.40      1264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RBM ve Logistic Regression pipeline'ı oluşturma\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "model.fit(X_train_rbm, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_rbm)\n",
    "\n",
    "# Model performansını ölçme\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "       BASKILI       0.57      0.05      0.09        83\n",
      "           DÜZ       0.53      0.99      0.69       660\n",
      "         DİĞER       0.33      0.02      0.04       209\n",
      "METRAJ BASKILI       0.00      0.00      0.00       104\n",
      "           YOK       0.44      0.03      0.06       128\n",
      "       ÇİZGİLİ       0.00      0.00      0.00        80\n",
      "\n",
      "      accuracy                           0.53      1264\n",
      "     macro avg       0.31      0.18      0.15      1264\n",
      "  weighted avg       0.41      0.53      0.38      1264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RBM ve Logistic Regression pipeline'ı oluşturma\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "model.fit(X_train_rbm_128, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_rbm_128)\n",
    "\n",
    "# Model performansını ölçme\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "       BASKILI       0.00      0.00      0.00        83\n",
      "           DÜZ       0.52      0.99      0.69       660\n",
      "         DİĞER       0.30      0.01      0.03       209\n",
      "METRAJ BASKILI       0.80      0.04      0.07       104\n",
      "           YOK       0.67      0.02      0.03       128\n",
      "       ÇİZGİLİ       0.00      0.00      0.00        80\n",
      "\n",
      "      accuracy                           0.52      1264\n",
      "     macro avg       0.38      0.18      0.14      1264\n",
      "  weighted avg       0.46      0.52      0.37      1264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RBM ve Logistic Regression pipeline'ı oluşturma\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "model.fit(X_train_128rbm, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_128rbm)\n",
    "\n",
    "# Model performansını ölçme\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "       BASKILI       0.29      0.02      0.04        83\n",
      "           DÜZ       0.53      0.97      0.69       660\n",
      "         DİĞER       0.36      0.06      0.10       209\n",
      "METRAJ BASKILI       1.00      0.04      0.07       104\n",
      "           YOK       0.72      0.10      0.18       128\n",
      "       ÇİZGİLİ       0.00      0.00      0.00        80\n",
      "\n",
      "      accuracy                           0.53      1264\n",
      "     macro avg       0.48      0.20      0.18      1264\n",
      "  weighted avg       0.51      0.53      0.40      1264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RBM ve Logistic Regression pipeline'ı oluşturma\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "model.fit(X_train_512rbm, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_512rbm)\n",
    "\n",
    "# Model performansını ölçme\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced RBM-Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "       BASKILI       0.22      0.17      0.19        83\n",
      "           DÜZ       0.56      0.04      0.07       660\n",
      "         DİĞER       0.26      0.10      0.14       209\n",
      "METRAJ BASKILI       0.22      0.12      0.15       104\n",
      "           YOK       0.12      0.72      0.20       128\n",
      "       ÇİZGİLİ       0.10      0.29      0.15        80\n",
      "\n",
      "      accuracy                           0.15      1264\n",
      "     macro avg       0.25      0.24      0.15      1264\n",
      "  weighted avg       0.38      0.15      0.11      1264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=42)\n",
    "\n",
    "# Modeli eğitme\n",
    "model.fit(X_train_rbm, y_train)\n",
    "\n",
    "# Test seti üzerinde tahmin yapma\n",
    "y_pred = model.predict(X_test_rbm)\n",
    "\n",
    "# Model performansını ölçme\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBM-LightGBM Model:\n",
    "Best and simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 55863\n",
      "[LightGBM] [Info] Number of data points in the train set: 5054, number of used features: 256\n",
      "[LightGBM] [Info] Start training from score -2.719793\n",
      "[LightGBM] [Info] Start training from score -0.649401\n",
      "[LightGBM] [Info] Start training from score -1.798111\n",
      "[LightGBM] [Info] Start training from score -2.502069\n",
      "[LightGBM] [Info] Start training from score -2.293525\n",
      "[LightGBM] [Info] Start training from score -2.759614\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "       BASKILI       0.26      0.10      0.14        83\n",
      "           DÜZ       0.55      0.92      0.69       660\n",
      "         DİĞER       0.40      0.10      0.16       209\n",
      "METRAJ BASKILI       0.54      0.12      0.20       104\n",
      "           YOK       0.67      0.16      0.25       128\n",
      "       ÇİZGİLİ       0.27      0.05      0.08        80\n",
      "\n",
      "      accuracy                           0.53      1264\n",
      "     macro avg       0.45      0.24      0.26      1264\n",
      "  weighted avg       0.50      0.53      0.44      1264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier(random_state=42, force_col_wise=True)\n",
    "\n",
    "# Modeli eğitme\n",
    "model.fit(X_train_rbm, y_train)\n",
    "\n",
    "# Test seti üzerinde tahmin yapma\n",
    "y_pred = model.predict(X_test_rbm)\n",
    "\n",
    "# Model performansını ölçme\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBM-LightGBM Balanced Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 55863\n",
      "[LightGBM] [Info] Number of data points in the train set: 5054, number of used features: 256\n",
      "[LightGBM] [Info] Start training from score -2.719793\n",
      "[LightGBM] [Info] Start training from score -0.649401\n",
      "[LightGBM] [Info] Start training from score -1.798111\n",
      "[LightGBM] [Info] Start training from score -2.502069\n",
      "[LightGBM] [Info] Start training from score -2.293525\n",
      "[LightGBM] [Info] Start training from score -2.759614\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "       BASKILI       0.26      0.10      0.14        83\n",
      "           DÜZ       0.55      0.92      0.69       660\n",
      "         DİĞER       0.40      0.10      0.16       209\n",
      "METRAJ BASKILI       0.54      0.12      0.20       104\n",
      "           YOK       0.67      0.16      0.25       128\n",
      "       ÇİZGİLİ       0.27      0.05      0.08        80\n",
      "\n",
      "      accuracy                           0.53      1264\n",
      "     macro avg       0.45      0.24      0.26      1264\n",
      "  weighted avg       0.50      0.53      0.44      1264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RBM ve Logistic Regression pipeline'ı oluşturma\n",
    "model = LGBMClassifier(random_state=42, is_unbalance=True, force_col_wise=True)\n",
    "\n",
    "# Modeli eğitme\n",
    "model.fit(X_train_rbm, y_train)\n",
    "\n",
    "# Test seti üzerinde tahmin yapma\n",
    "y_pred = model.predict(X_test_rbm)\n",
    "\n",
    "# Model performansını ölçme\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBM-LightGBM F1-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 55863\n",
      "[LightGBM] [Info] Number of data points in the train set: 5054, number of used features: 256\n",
      "[LightGBM] [Info] Start training from score -2.719793\n",
      "[LightGBM] [Info] Start training from score -0.649401\n",
      "[LightGBM] [Info] Start training from score -1.798111\n",
      "[LightGBM] [Info] Start training from score -2.502069\n",
      "[LightGBM] [Info] Start training from score -2.293525\n",
      "[LightGBM] [Info] Start training from score -2.759614\n",
      "F1-Score: 0.25504301422513254\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "       BASKILI       0.26      0.10      0.14        83\n",
      "           DÜZ       0.55      0.92      0.69       660\n",
      "         DİĞER       0.40      0.10      0.16       209\n",
      "METRAJ BASKILI       0.54      0.12      0.20       104\n",
      "           YOK       0.67      0.16      0.25       128\n",
      "       ÇİZGİLİ       0.27      0.05      0.08        80\n",
      "\n",
      "      accuracy                           0.53      1264\n",
      "     macro avg       0.45      0.24      0.26      1264\n",
      "  weighted avg       0.50      0.53      0.44      1264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Custom F1-score metric for LightGBM\n",
    "def f1_metric_lgbm(y_true, y_pred):\n",
    "    # Convert LightGBM predictions to predicted class indices\n",
    "    y_pred_classes = np.argmax(y_pred.reshape(len(np.unique(y_true)), -1), axis=0)\n",
    "    \n",
    "    # Calculate F1 score using sklearn's f1_score\n",
    "    f1 = f1_score(y_true, y_pred_classes, average=\"macro\")\n",
    "    \n",
    "    # Return in LightGBM's expected format (name, value, is_higher_better)\n",
    "    return \"f1\", f1, True\n",
    "\n",
    "# Initialize LightGBM with multiclass objective\n",
    "model = LGBMClassifier(\n",
    "    objective=\"multiclass\",\n",
    "    num_class=len(label_encoder.classes_),\n",
    "    random_state=42,\n",
    "    is_unbalance=True,\n",
    "    force_col_wise=True,\n",
    ")\n",
    "\n",
    "# Fit model with the custom evaluation metric\n",
    "model.fit(\n",
    "    X_train_rbm,\n",
    "    y_train,\n",
    "    eval_set=[(X_test_rbm, y_test)],\n",
    "    eval_metric=f1_metric_lgbm,  # Pass custom F1 metric here\n",
    ")\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_probs = model.predict_proba(X_test_rbm)  # Get probabilities for each class\n",
    "y_pred = y_pred_probs.argmax(axis=1)  # Convert probabilities to class predictions\n",
    "\n",
    "# Compute F1-score using scikit-learn\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "print(f\"F1-Score: {f1}\")\n",
    "\n",
    "# Model performance report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 55863\n",
      "[LightGBM] [Info] Number of data points in the train set: 5054, number of used features: 256\n",
      "[LightGBM] [Info] Start training from score -1.791759\n",
      "[LightGBM] [Info] Start training from score -1.791759\n",
      "[LightGBM] [Info] Start training from score -1.791759\n",
      "[LightGBM] [Info] Start training from score -1.791759\n",
      "[LightGBM] [Info] Start training from score -1.791759\n",
      "[LightGBM] [Info] Start training from score -1.791759\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "       BASKILI       0.24      0.11      0.15        83\n",
      "           DÜZ       0.59      0.28      0.38       660\n",
      "         DİĞER       0.34      0.12      0.18       209\n",
      "METRAJ BASKILI       0.38      0.16      0.23       104\n",
      "           YOK       0.12      0.70      0.20       128\n",
      "       ÇİZGİLİ       0.16      0.07      0.10        80\n",
      "\n",
      "      accuracy                           0.26      1264\n",
      "     macro avg       0.30      0.24      0.21      1264\n",
      "  weighted avg       0.43      0.26      0.28      1264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "# Sınıf ağırlıklarını hesapla\n",
    "class_counts = Counter(y_train)\n",
    "total_samples = len(y_train)\n",
    "class_weights = {cls: total_samples / count for cls, count in class_counts.items()}\n",
    "\n",
    "# Initialize LightGBM with multiclass objective\n",
    "model = LGBMClassifier(\n",
    "    objective=\"multiclass\",\n",
    "    num_class=len(label_encoder.classes_),\n",
    "    random_state=42,\n",
    "    class_weight=class_weights,\n",
    "    force_col_wise=True,\n",
    ")\n",
    "\n",
    "# Fit model with the custom evaluation metric\n",
    "model.fit(\n",
    "    X_train_rbm,\n",
    "    y_train,\n",
    "    eval_set=[(X_test_rbm, y_test)]\n",
    ")\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_probs = model.predict_proba(X_test_rbm)  # Get probabilities for each class\n",
    "y_pred = y_pred_probs.argmax(axis=1)  # Convert probabilities to class predictions\n",
    "\n",
    "# Model performance report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_, zero_division=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBM-SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "       BASKILI       0.00      0.00      0.00        83\n",
      "           DÜZ       0.52      1.00      0.69       660\n",
      "         DİĞER       0.00      0.00      0.00       209\n",
      "METRAJ BASKILI       0.00      0.00      0.00       104\n",
      "           YOK       0.00      0.00      0.00       128\n",
      "       ÇİZGİLİ       0.00      0.00      0.00        80\n",
      "\n",
      "      accuracy                           0.52      1264\n",
      "     macro avg       0.09      0.17      0.11      1264\n",
      "  weighted avg       0.27      0.52      0.36      1264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\", random_state=42)\n",
    "\n",
    "# Model eğitme\n",
    "model.fit(X_train_rbm, y_train)\n",
    "\n",
    "# Tahmin yapma\n",
    "y_pred = model.predict(X_test_rbm)\n",
    "\n",
    "# Performans raporu\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplest Best Model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 55863\n",
      "[LightGBM] [Info] Number of data points in the train set: 5054, number of used features: 256\n",
      "[LightGBM] [Info] Start training from score -2.719793\n",
      "[LightGBM] [Info] Start training from score -0.649401\n",
      "[LightGBM] [Info] Start training from score -1.798111\n",
      "[LightGBM] [Info] Start training from score -2.502069\n",
      "[LightGBM] [Info] Start training from score -2.293525\n",
      "[LightGBM] [Info] Start training from score -2.759614\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "       BASKILI       0.26      0.10      0.14        83\n",
      "           DÜZ       0.55      0.92      0.69       660\n",
      "         DİĞER       0.40      0.10      0.16       209\n",
      "METRAJ BASKILI       0.54      0.12      0.20       104\n",
      "           YOK       0.67      0.16      0.25       128\n",
      "       ÇİZGİLİ       0.27      0.05      0.08        80\n",
      "\n",
      "      accuracy                           0.53      1264\n",
      "     macro avg       0.45      0.24      0.26      1264\n",
      "  weighted avg       0.50      0.53      0.44      1264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier(random_state=42, force_col_wise=True)\n",
    "\n",
    "# Modeli eğitme\n",
    "model.fit(X_train_rbm, y_train)\n",
    "\n",
    "# Test seti üzerinde tahmin yapma\n",
    "y_pred = model.predict(X_test_rbm)\n",
    "\n",
    "# Model performansını ölçme\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Based Threshold Tuning\n",
    "\n",
    "Stick to the default thresholds !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Thresholds and F1-Scores for each class:\n",
      "Class: BASKILI, Best Threshold: 0.1, Best F1-Score: 0.2097902097902098\n",
      "Class: DÜZ, Best Threshold: 0.2, Best F1-Score: 0.6975476839237057\n",
      "Class: DİĞER, Best Threshold: 0.1, Best F1-Score: 0.32493483927019984\n",
      "Class: METRAJ BASKILI, Best Threshold: 0.2, Best F1-Score: 0.25149700598802394\n",
      "Class: YOK, Best Threshold: 0.4, Best F1-Score: 0.2641509433962264\n",
      "Class: ÇİZGİLİ, Best Threshold: 0.8, Best F1-Score: 0.09411764705882353\n"
     ]
    }
   ],
   "source": [
    "best_thresholds = {}\n",
    "best_f1_scores = {}\n",
    "\n",
    "# Iterate through each class\n",
    "for class_idx in range(len(label_encoder.classes_)):\n",
    "    best_threshold = 0.0\n",
    "    best_f1 = 0.0\n",
    "\n",
    "    for threshold in np.arange(0.1, 0.9, 0.1):\n",
    "        # Get the predicted probabilities for the current class\n",
    "        y_pred_binary = (model.predict_proba(X_test_rbm)[:, class_idx] > threshold).astype(int)\n",
    "        \n",
    "        # Create binary labels for the current class\n",
    "        y_val_binary = (y_test == class_idx).astype(int)\n",
    "        \n",
    "        # Calculate F1 score\n",
    "        current_f1 = f1_score(y_val_binary, y_pred_binary, average=\"binary\")\n",
    "        \n",
    "        if current_f1 > best_f1:\n",
    "            best_f1 = current_f1\n",
    "            best_threshold = threshold\n",
    "\n",
    "    # Store the best threshold and F1 score for the current class\n",
    "    best_thresholds[label_encoder.classes_[class_idx]] = best_threshold\n",
    "    best_f1_scores[label_encoder.classes_[class_idx]] = best_f1\n",
    "\n",
    "# Print the results\n",
    "print(\"Best Thresholds and F1-Scores for each class:\")\n",
    "for cls in label_encoder.classes_:\n",
    "    print(f\"Class: {cls}, Best Threshold: {best_thresholds[cls]}, Best F1-Score: {best_f1_scores[cls]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_custom = np.zeros_like(y_pred_probs.argmax(axis=1))\n",
    "for class_idx, threshold in enumerate([0.1, 0.2, 0.1, 0.2, 0.4, 0.8]):\n",
    "    y_pred_custom[(y_pred_probs[:, class_idx] > threshold)] = class_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report with Custom Thresholds:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "       BASKILI       0.24      0.06      0.10        83\n",
      "           DÜZ       0.62      0.15      0.24       660\n",
      "         DİĞER       0.19      0.88      0.32       209\n",
      "METRAJ BASKILI       0.27      0.24      0.25       104\n",
      "           YOK       0.58      0.16      0.26       128\n",
      "       ÇİZGİLİ       0.50      0.05      0.09        80\n",
      "\n",
      "      accuracy                           0.27      1264\n",
      "     macro avg       0.40      0.26      0.21      1264\n",
      "  weighted avg       0.49      0.27      0.24      1264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate classification report\n",
    "print(\"Classification Report with Custom Thresholds:\")\n",
    "print(classification_report(y_test, y_pred_custom, target_names=label_encoder.classes_, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FashionClip Model\n",
    "\n",
    "to be continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clip import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[133], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the CLIP model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model, preprocess \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mViT-B/32\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DUYGU.CAN\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\attr-extract-pI5zXQJo-py3.12\\Lib\\site-packages\\clip\\clip.py:120\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, device, jit, download_root)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a CLIP model\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    A torchvision transform that converts a PIL image into a tensor that the returned model can take as its input\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _MODELS:\n\u001b[1;32m--> 120\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m \u001b[43m_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MODELS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpanduser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m~/.cache/clip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(name):\n\u001b[0;32m    122\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m name\n",
      "File \u001b[1;32mc:\\Users\\DUYGU.CAN\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\attr-extract-pI5zXQJo-py3.12\\Lib\\site-packages\\clip\\clip.py:59\u001b[0m, in \u001b[0;36m_download\u001b[1;34m(url, root)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdownload_target\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m exists, but the SHA256 checksum does not match; re-downloading the file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m source, \u001b[38;5;28mopen\u001b[39m(download_target, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m output:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(source\u001b[38;5;241m.\u001b[39minfo()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Length\u001b[39m\u001b[38;5;124m\"\u001b[39m)), ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miB\u001b[39m\u001b[38;5;124m'\u001b[39m, unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, unit_divisor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m loop:\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[132], line 10\u001b[0m, in \u001b[0;36mcustom_urlopen\u001b[1;34m(timeout, *args, **kwargs)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcustom_urlopen\u001b[39m(\u001b[38;5;241m*\u001b[39margs, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_original_urlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[131], line 9\u001b[0m, in \u001b[0;36mcustom_urlopen\u001b[1;34m(timeout, *args, **kwargs)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcustom_urlopen\u001b[39m(\u001b[38;5;241m*\u001b[39margs, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_original_urlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[130], line 9\u001b[0m, in \u001b[0;36mcustom_urlopen\u001b[1;34m(timeout, *args, **kwargs)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcustom_urlopen\u001b[39m(\u001b[38;5;241m*\u001b[39margs, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal_urlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[129], line 8\u001b[0m, in \u001b[0;36mcustom_urlopen\u001b[1;34m(timeout, *args, **kwargs)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcustom_urlopen\u001b[39m(\u001b[38;5;241m*\u001b[39margs, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal_urlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[129], line 8\u001b[0m, in \u001b[0;36mcustom_urlopen\u001b[1;34m(timeout, *args, **kwargs)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcustom_urlopen\u001b[39m(\u001b[38;5;241m*\u001b[39margs, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal_urlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping similar frames: custom_urlopen at line 8 (2969 times)]\u001b[0m\n",
      "Cell \u001b[1;32mIn[129], line 8\u001b[0m, in \u001b[0;36mcustom_urlopen\u001b[1;34m(timeout, *args, **kwargs)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcustom_urlopen\u001b[39m(\u001b[38;5;241m*\u001b[39margs, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal_urlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "# Load the CLIP model\n",
    "model, preprocess = load(\"ViT-B/32\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attr-extract-pI5zXQJo-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
